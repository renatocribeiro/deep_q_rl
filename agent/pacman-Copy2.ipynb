{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Authors: Aleksey Grinchuk (AlexGrinch), Mariya Popova (Mariewelt) ... and some hedgehog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS='device=cpu'\n"
     ]
    }
   ],
   "source": [
    "#from __future__ import print_function \n",
    "experiment_setup_name = \"tutorial.gym.atari.Seaquest-ram-v0.rnn\"\n",
    "\n",
    "\n",
    "#gym game title\n",
    "GAME_TITLE = 'Seaquest-ram-v0'\n",
    "\n",
    "#how many parallel game instances can your machine tolerate\n",
    "N_PARALLEL_GAMES = 5\n",
    "\n",
    "#how long is one replay session from a batch\n",
    "#since we have window-like memory (no recurrent layers), we can use relatively small session weights\n",
    "replay_seq_len = 50\n",
    "\n",
    "\n",
    "#theano device selection. GPU is, as always, in preference, but not required\n",
    "%env THEANO_FLAGS='device=cpu'\n",
    "\n",
    "#number of bytes in RAM\n",
    "RAM_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This tutorial is a showcase on how to use AgentNet for OpenAI Gym environments\n",
    "\n",
    "\n",
    "* Pacman game as an example\n",
    "* Training a simple lasagne neural network for Q_learning objective\n",
    " * This example can be easily modified to use more difficult convolutional networks and/or recurrent agent memory. \n",
    " \n",
    "* Training via simple experience replay (explained below)\n",
    "* Only using utility recurrent layers for simplicity of this example\n",
    " * but adding a few RNNs or GRUs shouldn's be a problem\n",
    "* the network is trained with a simple ten-step Q-learning for simplicity\n",
    "\n",
    "\n",
    "## About OpenAI Gym\n",
    "\n",
    "* Its a recently published platform that basicly allows you to train agents in a wide variety of environments with near-identical interface.\n",
    "* This is twice as awesome since now we don't need to write a new wrapper for every game\n",
    "* Go check it out!\n",
    "  * Blog post - https://openai.com/blog/openai-gym-beta/\n",
    "  * Github - https://github.com/openai/gym\n",
    "  \n",
    "### Installing it\n",
    " * If nothing changed on their side, to run this, you bacically need to follow their install instructions - \n",
    " \n",
    "```\n",
    "git clone https://github.com/openai/gym.git\n",
    "cd gym\n",
    "pip install -e .[all]\n",
    "```\n",
    "\n",
    "## New to AgentNet and Lasagne?\n",
    "* This is pretty much the basic tutorial for AgentNet, so it's okay not to know it.\n",
    "* We only require surface level knowledge of theano and lasagne, so you can just learn them as you go.\n",
    "* Alternatively, you can find Lasagne tutorials here:\n",
    " * Official mnist example: http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    " * From scratch: https://github.com/ddtm/dl-course/tree/master/Seminar4\n",
    " * From theano: https://github.com/craffel/Lasagne-tutorial/blob/master/examples/tutorial.ipynb\n",
    "\n",
    "\n",
    "## The library\n",
    "\n",
    "In this notebook we shall use [AgentNet](https://github.com/BladeCarrier/AgentNet/) library.\n",
    "Agentnet, in essence, is an additional kit of lasagne layers that allow you to build custom recurrent layers.\n",
    "Assuming you already have Bleeding Edge theano and lasagne, you can install it via\n",
    "```\n",
    "git clone https://github.com/yandexdataschool/AgentNet\n",
    "cd AgentNet\n",
    "python setup.py install\n",
    "```\n",
    "in whatever python, environment or container you exist. Alternatively, see docker install instructions in the [readme](https://github.com/yandexdataschool/AgentNet/blob/master/README.md).\n",
    "\n",
    "\n",
    "Depending what python version do you use, in may be \n",
    "* `python3 setup.py install` \\ `python2 setup.py install` if you are using a different python\n",
    "* add sudo - `sudo python setup.py install` - if you have a superuser-installed python\n",
    "* in case you have any problems - contact us or consider using a docker container (see above).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions allow us to preprocess original images from size of 210x160x3 (RGB images) to size of 110x84 (grayscale images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocess(image):\n",
    "    def_h = 84\n",
    "    def_w = 110\n",
    "    img = 0.299*image[:,:,0] + 0.587*image[:,:,1] + 0.114*image[:,:,2]\n",
    "    img = cv2.resize(img, (def_h, def_w))\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_tensor(tensor):\n",
    "    def_h = 84\n",
    "    def_w = 110\n",
    "    tnsr = np.zeros((tensor.shape[0], tensor.shape[1], def_w, def_h, 1))\n",
    "    for i in xrange(tensor.shape[0]):\n",
    "        for j in xrange(tensor.shape[1]):\n",
    "            img = 0.299*tensor[i,j,:,:,0] + 0.587*tensor[i,j,:,:,1] + 0.114*tensor[i,j,:,:,2]\n",
    "            tnsr[i,j,:,:,0] = cv2.resize(img, (def_h, def_w))\n",
    "    return tnsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_tensor4(tensor):\n",
    "    def_h = 84\n",
    "    def_w = 110\n",
    "    tnsr = np.zeros((tensor.shape[0], def_w, def_h, 1))\n",
    "    for i in xrange(tensor.shape[0]):\n",
    "        img = 0.299*tensor[i,:,:,0] + 0.587*tensor[i,:,:,1] + 0.114*tensor[i,:,:,2]\n",
    "        tnsr[i,:,:,0] = cv2.resize(img, (def_h, def_w))\n",
    "    return tnsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-10 16:31:36,449] Making new env: Seaquest-ram-v0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a31bc4fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM8AAAEACAYAAAAUSCKKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a33c7bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "atari = gym.make(GAME_TITLE)\n",
    "atari.reset()\n",
    "plt.imshow(atari.render('rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a1d3ba210>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM8AAAD/CAYAAABW+4LyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEQ9JREFUeJzt3X2QVfV9x/H3BxFxF8XFDuBzxCggtgmMRSc00aloMWlE\nM+NDYnzCNn80jU6apkpmkuavJulMxnEyTSZJlSKaVjFGcCYJBLGJScanAGpEUAuiqKwyMhhWRwS/\n/eOcu0/uwu733OXeXT6vmTvcc+653/O7d/nwPfdw93cUEZjZ4I1q9ADMhiuHxyzJ4TFLcnjMkhwe\nsySHxyxpyMIjaZ6kDZKek3TTUO3HrFE0FP/PI2kU8BxwHvAq8DhwRURsqPvOzBpkqDrPbOD5iNgS\nEe8B/wPMH6J9mTXEUIXnOODlbstby3VmI8boRu1Ykr8XZMNGRKj3uqHqPK8AJ3ZbPr5cZzZiDFV4\nHgc+LOkkSWOAK4DlQ7Qvs4YYksO2iNgr6R+BlRQBvS0inh2KfZk1ypCcqh7Qjv2Zx4aRvj7zNOyE\nwf6MHz++0UMwA2Dnzp19rvfXc8ySmrbznH/++Y0eggFjx479wP333nsPgI6OjoaM6UC79957+1zv\nzmOW1LSdx5rDkiVLOu9feumlACxdurTH8sHKnccsyeExS3J4zJIcHrMkh8csyWfbbJ9+85vfdN7/\n+te/DsBzzz3XqOE0FXcesyR3Htun733ve40eQtNy5zFLcnjMkhwesySHp0nMnj2b2bNn9/v4vHnz\nmDdvXr+Pz5gxgxkzZgzF0KwfDo9Zks+2NVjt95ZmzpwJwGOPPdbj8dGjix/R9ddfD8Avf/nLPut8\n85vfBPxN5wPJnccsyZ3nAPrCF74AwGGHHda57hOf+ESPbU499VQAjjnmGAC+9KUv9Xj8hBNOAGDW\nrFkAfP7zn+/x+NVXXw3AHXfcUa9hWz/cecySHB6zJB+2NUDvQzWAd955p8dy78O1mt27dwMfPFyr\n2bFjR8XR2UC585glufMcQLXusq/TySeffPJ+twH4xje+AcCzz3oW40Zx5zFLcuc5gLpP49SfzZs3\nD6iWO07jufOYJTVt52ltbW30EMz2yZ3HLKlpO48vMWLNLt15JB0vabWkZyQ9LemGcn2bpJWSNkpa\nIckpsBGpSufZA/xTRKyTNA74g6SVwHXAqoj4d0k3AQuBmwdb3J95rNmlO09EbIuIdeX9XcCzFFe9\nng8sLjdbDFxcdZBmzaguJwwkfQj4KPAIMCki2qEIGDCxHvswazaVTxiUh2z3AjdGxK4+LtTrC/fa\nsLJlyxZeeuml/W5XKTySRlMEZ0lELCtXt0uaFBHtkiYDr2dqt7S0VBmaWdr06dOZPn165/Jvf/vb\nPrereth2O7A+Im7ttm45cG15/xpgWe8nmY0E6c4jaQ5wJfC0pLUUh2dfA74D3CNpAbAFuCxTf9y4\ncdmhmR0Q6fBExO+AQ/p5eG62rtlw0bTfMNi1a1ejh2C2T/5um1lS03aeZct8nqEepk2bBsC3vvUt\nAC655JJGDmdEcecxS2razrNnz55GD2FEqHWcGr+v9ePOY5bUtJ3nuOOOa/QQhoW2tjaga7622nJ/\nzjjjjB7LO3fuBOD9998fgtGNDOvWretzvTuPWZIiGvO9zT6+QNrD6aeffqCGMqytWLGi0vOvuuoq\nAF5/PfUVxIPC+vXriQj1Xu/OY5bUtJ95Ro1yrgfiwgsvrEsdv9+D53fMLKlpO8/bb7/d6CGY7ZM7\nj1lS03aesWPHNnoIZvvkzmOW5PCYJTk8ZkkOj1mSw2OW5PCYJTk8ZkkOj1mSw2OW5PCYJTk8ZkkO\nj1mSw2OW5PCYJTk8ZkkOj1lS5fBIGiVpjaTl5XKbpJWSNkpaIWl89WGaNZ96dJ4bgfXdlm8GVkXE\nVGA1sLAO+zBrOpXCI+l44JPAf3ZbPR9YXN5fDFxcZR9mzapq57kF+Co9Lxc/KSLaASJiGzCx4j7M\nmlI6PJI+BbRHxDrgA1ORdtOY+XzNhliV2XPmABdJ+iRwOHCEpCXANkmTIqJd0mTAkyDbsNLR0UFH\nR8d+t0t3noj4WkScGBFTgCuA1RFxFfAAcG252TWAr49ow0praysTJ07svPVnKP6f59vA+ZI2AueV\ny2YjTl0mPYyIXwO/Lu+/CcytR12zZuZvGJglOTxmSQ6PWZLDY5bk8JglOTxmSQ6PWZLDY5bk8Jgl\nOTxmSQ6PWZLDY5bk8JglOTxmSQ6PWZLDY5bk8JglOTxmSQ6PWZLDY5bk8JglOTxmSQ6PWZLDY5bk\n8JglOTxmSQ6PWZLDY5bk8JglOTxmSQ6PWZLDY5ZU9VLy4yUtlfSspGcknSWpTdJKSRslrZA0vl6D\nNWsmVTvPrcDPI2I68BFgA3AzsCoipgKrgYUV92HWlKpcSv5I4OMRsQggIvZExE5gPrC43GwxcHHl\nUZo1oSqd52Rgu6RFktZI+pGkFmBSRLQDRMQ2oP/LCZsNY1Uu6DsamAV8MSKekHQLxSFb9Nqu97JZ\nU+vo6KCjo2O/21UJz1bg5Yh4olz+KUV42iVNioh2SZOB1yvsw+yAa21tpbW1tXN5+/btfW6XPmwr\nD81elnRaueo84BlgOXBtue4aYFl2H2bNrErnAbgBuEvSocAm4DrgEOAeSQuALcBlFfdh1pQqhSci\nngT+so+H5lapazYc+BsGZkkOj1mSw2OW5PCYJTk8ZkkOj1mSw2OW5PCYJTk8ZkkOj1mSw2OW5PCY\nJTk8ZkkOj1mSw2OW5PCYJTk8ZkkOj1mSw2OW5PCYJTk8ZkkOj1mSw2OW5PCYJTk8ZkkOj1mSw2OW\n5PCYJTk8ZkkOj1mSw2OW5PCYJVUKj6SFkp6R9JSkuySNkdQmaaWkjZJWSBpfr8GaNZN0eCSdBPw9\nMDMi/oLiKnOfpbio76qImAqsBhbWY6BmzaZK53kL2A20ShoNHA68AswHFpfbLAYurjRCsyaVviZp\nROyQ9F3gJeBtYGVErKpdRr7cZpukiZn6LS0t2aGZHRDp8EiaAnwZOAnYCSyVdCUQvTbtvWzW1N56\n6y3+9Kc/7Xe7KlfDPhP4XUS8CSDpZ8DHgPZa95E0GXg9U3z06KpXuTfLmTBhAhMmTOhcfu211/rc\nrspnno3A2ZLGShJwHrAeWA5cW25zDbCswj7MmlaVzzxPSroD+AOwF1gL/Ag4ArhH0gJgC3BZpv6e\nPXuyQzM7IBTRmI8kkva54zPPPPNADcVsn5544gkiQr3X+xsGZkkOj1nSsDmltWDBAgCOOOKIPh9/\n9NFHO+8/8sgjQzqWG2+8cZ+P33777QADOt051GO59dZbh3wMtZ9J7WfUqLGcffbZnffPOuusPrep\n/UxqP6Mq3HnMkpr2hMGqVasq72PXrl1A13n62vLdd9+9z+ddf/31PZZPPfXUSuN49dVXAejo6ABg\nzZo1nY+tXbu2z+eMGzcOgMsvv7yuY3n++ed7LNfei9p709vMmTM778+aNQuA1tZWAI499ti6juW2\n227b5/a196L23hxzzDE9lodqLD5hYFZnI7rzmNXD3Llz3XnM6snhMUtyeMySHB6zJIfHLGnYfMOg\nt6985SsAnHvuuUBxLr6mra0NgA0bNgBdvxv04osvAnDOOecA8Pvf/x6AH//4xwDcf//9ALzxxhsA\nLFw4sOkXHnjggdRrGOk+/elPN3oIQ8qdxyxp2Haez3zmMwC8+eabABx++OGdj11yySUAbN26FYA5\nc+YA8LnPfQ6ABx98sMdz9u7dC3R1rxdeeAEYeOexg5M7j1nSsO08ixcXs1tdeeWVAMyYMaPzsYcf\nfhiAM844o8dzat+BOvLIIwEYO3Ys0NV5at9Qrn0WGqhaPTu4uPOYJfm7bWb74e+2mdWZw2OW5PCY\nJTk8ZkkOj1mSw2OW5PCYJTk8ZkkOj1mSw2OW5PCYJTk8Zkn7/ZUESbcBfwu0l5eMR1IbcDfF9Uhf\nBC6LiJ3lYwuBBcAe4MaIWJkZ2A9/+MPM08wOmIF0nkXA3/RadzOwKiKmAquBhQCSTqe4Etx04ELg\n++UlF81GnojY742iwzzVbXkDMKm8PxnYUN6/Gbip23a/AM7qp2b45ttwufX1dzj7mWdiRLRTVN0G\nTCzXHwe83G27V8p1ZiNOvX4NO+pUx0qnnHIKAJs2bQLgggsuAGDKlCk91tcu87Fo0SKAzkugz58/\nH+i6vEnN7t27AXjooYeGbOwHi2znaZc0CUDSZOD1cv0rwAndtju+XGc24gy086i81SwHrgW+A1wD\nLOu2/i5Jt1Acrn0YeKwuIz1ITJ48Gei6kNTmzZuBrslLahehamlpAbou3HXUUUcBXR1n+fLlAFx6\n6aVA13RaU6dOBbomR6n9Gv727dsBWLas+FHWOt8f//jHer68EWUgp6p/ApwLHC3pJeBfgW8DSyUt\nALZQnGEjItZLugdYD7wH/EM0apIEsyHWtBOAHKxqnaf2GefOO+8EYMyYMUBXJ6l1oHfeeQeAE04o\njpZrUwfPmzcPgKOPPhqAUaOKI/TaJREPPfTQPuvUpiquTd/lzlPwBCBmdTRsJz0cqWoTMN533309\n1l999dUA7NixA+g6a/buu+8CXR2npra+1mlqz6v9n3Wt89T+rD3+gx/8AIBp06bV5fWMZO48Zkn+\nzGM2AP7MY1ZHDo9ZksNjluTwmCU5PGZJDo9ZksNjluTwmCU5PGZJDo9ZksNjluTwmCU17IuhZsOd\nO49ZksNjltSw8EiaJ2mDpOck3ZR4/m2S2iU91W1dm6SVkjZKWiFp/CDqHS9ptaRnJD0t6YY61DxM\n0qOS1pZ1/61qzfL5oyStkbS8DmN8UdKT5Rgfq0O98ZKWSnq2fM1nVax3Wjm2NeWfOyXdULHmwnJs\nT0m6S9KYVL2BTLdb7xtFaF+gmMb3UGAdMG2QNf4K+Cg9pwH+DvAv5f2bgG8Pot5k4KPl/XHARmBa\nlZrlc1rKPw8BHgHm1KHml4E7geV1eN2bgLZe66rU+y/guvL+aGB81dfb6+/NqxRzA6Zqln/nNgFj\nyuW7KaZPG3S9RoXnbOAX3ZZ7zHE9iDonMYA5tJNjvB+YW6+aQAvFHHanV6lJMZHkryimA6uFp0q9\nzcDRvdal6gFHAv/Xx/p6vYcXAA9XHGNb+dy2MtzLsz/nRh229Z7Teiv1mdO6vzm0B0XShyi62iMU\nb2i6ZnmItRbYBvxvRKyvWPMW4Kv0nOK4Sr0AfiXpcUl/V7HeycB2SYvKw6wfSWqpOL7uLgd+UmWM\nEbED+C7wEsVstjsjYlWm3kg/YTDo8/CSxgH3UlxbaFcfNQZVMyLej4iZFB3j45LOzdaU9CmK6ySt\no+cMrh/Y7SCGOCciZgGfBL4o6ePZ8VH8Sz4L+I+yZgfFUUWl9xBA0qHARcDSfmoM9D2cQnHYexJw\nLNAq6cpMvUaF5xXgxG7L9ZrTur85tAdE0miK4CyJiNoUwpVq1kTEW8DPgTMr1JwDXCRpE/DfwF9L\nWgJsy44xIl4r/3yD4lB1doXxbQVejognyuWfUoSpHu/hhcAfImJ7uZyteSbwu4h4MyL2Aj8DPpap\n16jwPA58WNJJksYAV1Acew5Wf3NoQ885tAfqdmB9RNxaj5qS/qx21kbS4cD5wNpszYj4WkScGBFT\nKN6z1RFxFfBApp6klrLTIqmV4jPF0xXG1w68LOm0ctV5wDPZer18luIfjJpszY3A2ZLGqpjE7jyK\n6aEHXy/zwa0eN2Be+UKeB25OPP8nFGde3qU4fr2O4kPgqrLuSuCoQdSbA+ylOPO3FlhTjnFChZp/\nXtZZCzwJ/HO5Pl2zW+1z6DphkKpH8Rml9nqfrv0cKr7mj1D847gOuI/ibFul10txsuUN4Ihu66qM\n8asUoX4KWExxxnfQ9fz1HLOkkX7CwGzIODxmSQ6PWZLDY5bk8JglOTxmSQ6PWZLDY5b0/y6yryZt\nD8ZdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a6456dc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocess(atari.render('rgb_array'))[:,:,0], cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Parameters\n",
    "* observation dimensions, actions, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOOP', 'FIRE', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'UPRIGHT', 'UPLEFT', 'DOWNRIGHT', 'DOWNLEFT', 'UPFIRE', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "n_actions = atari.action_space.n\n",
    "observation_shape = (None,) + atari.observation_space.shape #(110, 84, 1)\n",
    "action_names = atari.get_action_meanings()\n",
    "print action_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del atari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent setup step by step\n",
    "* An agent implementation may contain these parts:\n",
    " * Observation(s)\n",
    "   * InputLayers where observed game states (here - images) are sent at each tick \n",
    " * Memory layer(s)\n",
    "   * A dictionary that maps \"New memory layers\" to \"prev memory layers\"\n",
    " * Policy layer (e.g. Q-values or probabilities)\n",
    "   * in this case, a lasagne dense layer based on observation layer\n",
    " * Resolver - acton picker layer\n",
    "   * chooses what action to take given Q-values\n",
    "   * in this case, the resolver has epsilon-greedy policy\n",
    "   \n",
    "   \n",
    "We are going to build something of this shape:\n",
    "\n",
    "(one can assume that the 'time' goes from left to right, inputs are at the bottom and outputs go to the top)\n",
    "\n",
    "\n",
    "\n",
    "![window_dqn_scheme](http://s32.postimg.org/yy5q3wadx/window_dqn.png)\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Agent observations\n",
    "\n",
    "* Here you define where observations (game images) appear in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import InputLayer, DimshuffleLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#image observation at current tick goes here\n",
    "observation_layer = InputLayer(observation_shape, name=\"RAM input\")\n",
    "\n",
    "\n",
    "#reshape to [batch, color, x, y] to allow for convolutional layers to work correctly\n",
    "observation_reshape = observation_layer # DimshuffleLayer(observation_layer,(0,3,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "### Agent memory states\n",
    " * Here you can define arbitrary transitions between \"previous state\" variables and their next states\n",
    " * The rules are\n",
    "   * previous states must be input layers\n",
    "   * next states must have same shape as previous ones\n",
    "   * otherwise it can be any lasagne network\n",
    "   * AgentNet.memory has several useful layers\n",
    "   \n",
    " * During training and evaluation, your states will be updated recurrently\n",
    "   * next state at t=1 is given as previous state to t=2\n",
    " \n",
    " * Finally, you have to define a dictionary mapping new state -> previous state\n",
    "\n",
    "\n",
    "### In this demo\n",
    "Since we have almost fully observable environment AND we want to keep baseline simple, we shall use no recurrent units.\n",
    "However, Atari game environments are known to have __flickering__ effect where some sprites are shown only on odd frames and others on even ones - that was used to optimize performance at the time.\n",
    "To compensate for this, we shall use the memory layer called __WindowAugmentation__ which basically maintains a K previous time steps of what it is fed with.\n",
    "\n",
    "One can try to use\n",
    " * GRU - `from agentnet.memory import GRUMemoryLayer`\n",
    " * RNN - `from agentnet.memory import RNNCell`\n",
    " * any custom lasagne layers that compute new memory states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#memory\n",
    "#using simple window-based memory that stores several states\n",
    "#the SpaceInvaders environment does not need any more as it is almost fully-observed\n",
    "from agentnet.memory import WindowAugmentation\n",
    "\n",
    "\n",
    "window_size = 5\n",
    "\n",
    "\n",
    "#prev state input\n",
    "prev_window = InputLayer((None,window_size)+tuple(observation_reshape.output_shape[1:]),\n",
    "                        name = \"previous window state\")\n",
    "\n",
    "\n",
    "#our window\n",
    "window = WindowAugmentation(observation_reshape,\n",
    "                            prev_window,\n",
    "                            name = \"new window state\")\n",
    "\n",
    "\n",
    "\n",
    "memory_dict = {window:prev_window}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural network body\n",
    "Our strategy, again:\n",
    " * take pixel-wise maximum over the window\n",
    " * apply some layers\n",
    " * use output layer to predict Q-values(see next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import DropoutLayer,DenseLayer, ExpressionLayer\n",
    "\"\"\"\n",
    "#you may use any other lasagne layers, including convolutions, batch_norms, maxout, etc\n",
    "\n",
    "#pixel-wise maximum over the temporal window (to avoid flickering)\n",
    "window_max = ExpressionLayer(window,\n",
    "                             lambda a: a.max(axis=1),\n",
    "                             output_shape = (None,)+window.output_shape[2:])\n",
    "\n",
    "\n",
    "\n",
    "#a simple lasagne network (try replacing with any other lasagne network and see what works best)    \n",
    "nn = lasagne.layers.Conv2DLayer(window_max, num_filters=16, filter_size=(8, 8), stride=(4, 4))\n",
    "nn = lasagne.layers.BatchNormLayer(nn)\n",
    "nn = lasagne.layers.Conv2DLayer(nn, num_filters=32, filter_size=(4, 4), stride=(2, 2))\n",
    "nn = lasagne.layers.BatchNormLayer(nn)\n",
    "nn = lasagne.layers.DenseLayer(nn, num_units=256)\n",
    "nn = lasagne.layers.BatchNormLayer(nn)\n",
    "\"\"\"\n",
    "#WARNING! if your network is computing too slowly, try decreasing the amount of neurons\n",
    "\n",
    "\n",
    "hidden_layer_1 = lasagne.layers.DenseLayer(observation_layer,\n",
    "                                           num_units=RAM_SIZE,\n",
    "                                           nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                                           W=lasagne.init.HeUniform(),\n",
    "                                           b=lasagne.init.Constant(.1))\n",
    "\n",
    "nn = lasagne.layers.DenseLayer(hidden_layer_1,\n",
    "                                           num_units=RAM_SIZE,\n",
    "                                           nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                                           W=lasagne.init.HeUniform(),\n",
    "                                           b=lasagne.init.Constant(.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Agent policy and action picking\n",
    "* Since we are training a deep Q-network, we need it to predict Q-values and take actions.\n",
    "* Hence we define a lasagne layer that is used for action output\n",
    "\n",
    "* To pick actions, we use an epsilon-greedy resolver\n",
    "  * Note that resolver outputs particular action IDs and not probabilities.\n",
    "  * These actions are than sent into the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#q_eval\n",
    "q_eval = DenseLayer(nn,\n",
    "                   num_units = n_actions,\n",
    "                   nonlinearity=lasagne.nonlinearities.linear,\n",
    "                   name=\"QEvaluator\")\n",
    "\n",
    "#resolver\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "resolver = EpsilonGreedyResolver(q_eval,name=\"resolver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layer,\n",
    "              {}, #memory_dict,\n",
    "              q_eval,resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, QEvaluator.W, QEvaluator.b]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(resolver,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent step function\n",
    "* computes action and next state given observation and prev state\n",
    "* written in a generic way to support any recurrences, windows, LTMs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile theano graph for one step decision making\n",
    "applier_fun = agent.get_react_function()\n",
    "\n",
    "#a nice pythonic interface\n",
    "\"\"\"\n",
    "def step(observation, prev_memories = 'zeros', batch_size = N_PARALLEL_GAMES):\n",
    "    # returns actions and new states given observation and prev state\n",
    "    # Prev state in default setup should be [prev window,]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #default to zeros\n",
    "    if prev_memories == 'zeros':\n",
    "        prev_memories = [np.zeros((batch_size,)+tuple(mem.output_shape[1:]),\n",
    "                                  dtype='float32') \n",
    "                         for mem in agent.state_variables]\n",
    "    \n",
    "    obs = preprocess_tensor4(np.array(observation))\n",
    "    obs = obs.astype(np.float32, copy=False)\n",
    "    res = applier_fun(obs,*prev_memories)\n",
    "    \n",
    "    action = res[0]\n",
    "    memories = res[1:]\n",
    "    return action, memories\n",
    "\"\"\"\n",
    "    \n",
    "def step(observation, prev_memories='zeros', batch_size=N_PARALLEL_GAMES):\n",
    "    \"\"\" returns actions and new states given observation and prev state\n",
    "    Prev state in default setup should be [prev window,]\"\"\"\n",
    "    #default to zeros\n",
    "    if prev_memories == 'zeros':\n",
    "        prev_memories = [np.zeros((batch_size,)+tuple(mem.output_shape[1:]),\n",
    "                         dtype='float32') for mem in agent.agent_states]\n",
    "    #print(\"prev memories:\", prev_memories)\n",
    "    res = applier_fun(np.array(observation), *prev_memories)\n",
    "    action = res[0]\n",
    "    memories = res[1:]\n",
    "#    print(\"new memories:\", memories)\n",
    "    return action, memories\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* We define a small container that stores\n",
    " * game emulators\n",
    " * last agent observations\n",
    " * agent memories at last time tick\n",
    "* This allows us to instantly continue a session from where it stopped\n",
    "\n",
    "\n",
    "\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-10 16:31:42,244] Making new env: Seaquest-ram-v0\n",
      "[2016-07-10 16:31:42,261] Making new env: Seaquest-ram-v0\n",
      "[2016-07-10 16:31:42,277] Making new env: Seaquest-ram-v0\n",
      "[2016-07-10 16:31:42,294] Making new env: Seaquest-ram-v0\n",
      "[2016-07-10 16:31:42,310] Making new env: Seaquest-ram-v0\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import GamePool\n",
    "\n",
    "pool = GamePool(GAME_TITLE, N_PARALLEL_GAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 116 ms, sys: 0 ns, total: 116 ms\n",
      "Wall time: 112 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "observation_log,action_log,reward_log,_,_,_  = pool.interact(step,50)\n",
    "\n",
    "#print(np.array(action_names)[np.array(action_log)[:3,:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience replay pool\n",
    "\n",
    "Since our network exists in a theano graph and OpenAI gym doesn't, we shall train out network via experience replay.\n",
    "\n",
    "To do that in AgentNet, one can use a SessionPoolEnvironment.\n",
    "\n",
    "It's simple: you record new sessions using `interact(...)`, and than immediately train on them.\n",
    "\n",
    "1. Interact with Atari, get play sessions\n",
    "2. Store them into session environment\n",
    "3. Train on them\n",
    "4. Repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create an environment with all default parameters\n",
    "from agentnet.environment import SessionPoolEnvironment\n",
    "env = SessionPoolEnvironment(observations = observation_layer,\n",
    "                             actions=resolver,\n",
    "                             agent_memories=agent.state_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def update_pool(env, pool,n_steps=100):\n",
    "    # a function that creates new sessions and ads them into the pool\n",
    "    # throwing the old ones away entirely for simplicity\n",
    "\n",
    "    preceding_memory_states = list(pool.prev_memory_states)\n",
    "    \n",
    "    #get interaction sessions\n",
    "    observation_tensor,action_tensor,reward_tensor,_,is_alive_tensor,_= pool.interact(step,n_steps=n_steps)\n",
    "    observation_tensor = preprocess_tensor(observation_tensor)\n",
    "    \n",
    "    #load them into experience replay environment\n",
    "    env.load_sessions(observation_tensor,action_tensor,reward_tensor,is_alive_tensor,preceding_memory_states)\n",
    "\"\"\"\n",
    "    \n",
    "def update_pool(env, pool, n_steps=replay_seq_len):\n",
    "    preceding_memory_states = list(pool.prev_memory_states)\n",
    "\n",
    "    #get interaction sessions\n",
    "    observation_tensor, action_tensor, reward_tensor, memory_logs, is_alive_tensor, _ = pool.interact(step, n_steps=n_steps)\n",
    "\n",
    "    \"\"\"print(preceding_memory_states)\n",
    "    print(\"here:\")\n",
    "    print(env.preceding_agent_memories)\n",
    "    print(len(env.preceding_agent_memories))\n",
    "    print(len(preceding_memory_states))\n",
    "    print(memory_logs)\n",
    "    print(memory_logs[0].shape)\"\"\"\n",
    "\n",
    "    #load them into experience replay environment\n",
    "    # print(\"obstensor shape: \", observation_tensor[0].shape)\n",
    "    # print(\"obs len:\", len(env.observations), \"obs shape: \", env.observations[0].get_value().shape)\n",
    "\n",
    "    env.append_sessions(observation_tensor/128., action_tensor, reward_tensor,\n",
    "                        is_alive_tensor, preceding_memory_states, max_pool_size=1e4)  # TODO: what does it mean?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henryk/AgentNet/agentnet/environment/session_pool.py:286: UserWarning: Warning! Appending sessions to empty or broken pool. Old pool sessions, if any, are disposed.\n",
      "  warn(\"Warning! Appending sessions to empty or broken pool. Old pool sessions, if any, are disposed.\")\n"
     ]
    }
   ],
   "source": [
    "#load first  sessions\n",
    "update_pool(env,pool,replay_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated way of training is to store a large pool of sessions and train on random batches of them. \n",
    "* Why that is expected to be better - http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html\n",
    "* Or less proprietary - https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf\n",
    "\n",
    "To do that, one might make use of\n",
    "* ```env.load_sessions(...)``` - load new sessions\n",
    "* ```env.get_session_updates(...)``` - does the same thing via theano updates (advanced)\n",
    "* ```batch_env = env.sample_session_batch(batch_size, ...)``` - create an experience replay environment that contains batch_size random sessions from env (rerolled each time). Should be used in training instead of env.\n",
    "* ```env.select_session_batch(indices)``` does the same thing deterministically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interacting with environment\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training via experience replay\n",
    "\n",
    "* We use agent we have created to replay environment interactions inside Theano\n",
    "* to than train on the replayed sessions via theano gradient propagation\n",
    "* this is essentially basic Lasagne code after the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "_,_,_,_,qvalues_seq = agent.get_sessions(\n",
    "    env,\n",
    "    session_length=replay_seq_len,\n",
    "    batch_size=env.batch_size,\n",
    "    optimize_experience_replay=True,\n",
    ")\n",
    "\n",
    "\n",
    "#The \"_\"s are\n",
    "#first - environment states - which is empty since we are using session pool as our environment\n",
    "#secund - observation sequences - whatever agent recieved at observation input(s) on each tick\n",
    "#third - a dictionary of all agent memory units (RNN, GRU, NTM) - empty as we use none of them\n",
    "#last - \"imagined\" actions - actions agent would pick now if he was in that situation \n",
    "#                              - irrelevant since we are replaying and not actually playing the game now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating loss function\n",
    "* In this part we are using some basic Reinforcement Learning methods (here - Q-learning) to train\n",
    "* AgentNet has plenty of such methods, but we shall use the simple Q_learning for now.\n",
    "* Later you can try:\n",
    " * SARSA - simpler on-policy algorithms\n",
    " * N-step q-learning (requires n_steps parameter)\n",
    " * Advantage Actor-Critic (requires state values and probabilities instead of Q-values)\n",
    "\n",
    "\n",
    "* The basic interface is .get_elementwise_objective \n",
    "  * it returns loss function (here - squared error against reference Q-values) values at each batch and tick\n",
    "  \n",
    "* If you want to do it the hard way instead, try .get_reference_Qvalues and compute errors on ya own\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "\n",
    "\n",
    "from agentnet.learning import qlearning\n",
    "from agentnet.learning import qlearning_n_step\n",
    "\n",
    "#gamma - delayed reward coefficient - what fraction of reward is retained if it is obtained one tick later\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#IMPORTANT!\n",
    "# If you are training on a game that has rewards far outside some [-5,+5]\n",
    "# it is a good idea to downscale them to avoid divergence\n",
    "scaled_reward_seq = env.rewards\n",
    "#For SpaceInvaders, however, not scaling rewards is at least working\n",
    "\n",
    "\n",
    "\"\"\"elwise_mse_loss = qlearning_n_step.get_elementwise_objective(qvalues_seq,\n",
    "                                                        env.actions[0],\n",
    "                                                        scaled_reward_seq,\n",
    "                                                        env.is_alive,\n",
    "                                                        n_steps=10,\n",
    "                                                        gamma_or_gammas=0.99,)\"\"\"\n",
    "\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                        env.actions[0],\n",
    "                                                        scaled_reward_seq,\n",
    "                                                        env.is_alive,\n",
    "                                                        gamma_or_gammas=0.99,)\n",
    "\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "mse_loss = elwise_mse_loss.sum() / env.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#regularize network weights\n",
    "\n",
    "from lasagne.regularization import regularize_network_params, l2\n",
    "reg_l2 = regularize_network_params(resolver,l2)*10**-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = mse_loss + reg_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.adadelta(loss,weights,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mean session reward\n",
    "mean_session_reward = env.rewards.sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile train and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "train_fun = theano.function([],[loss,mean_session_reward],updates=updates)\n",
    "evaluation_fun = theano.function([],[loss,mse_loss,reg_l2,mean_session_reward])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session visualization tools\n",
    "\n",
    "Just a helper function that draws current game images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_sessions(max_n_sessions = 3):\n",
    "    \"\"\"just draw random images\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=[15,8])\n",
    "    \n",
    "    pictures = [atari.render(\"rgb_array\") for atari in pool.games[:max_n_sessions]]\n",
    "    for i,pic in enumerate(pictures):\n",
    "        plt.subplot(1,max_n_sessions,i+1)\n",
    "        plt.imshow(pic)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAFjCAYAAABMu/jqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f89e11f51d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize untrained network performance (which is mostly random)\n",
    "display_sessions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.display import Metrics\n",
    "score_log = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "#moving average estimation\n",
    "alpha = 0.1\n",
    "ma_reward_current = 0.\n",
    "ma_reward_greedy = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_epochs = 10000\n",
    "#25k may take hours to train.\n",
    "#consider interrupt early.\n",
    "\n",
    "\n",
    "\n",
    "for i in range(n_epochs):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    update_pool(env,pool,replay_seq_len)\n",
    "    resolver.rng.seed(i)    \n",
    "    loss,avg_reward = train_fun()\n",
    "    \n",
    "    \n",
    "    ##update resolver's epsilon (chance of random action instead of optimal one)\n",
    "    if epoch_counter%1 ==0:\n",
    "        current_epsilon = 0.05 + 0.45*np.exp(-epoch_counter/1000.)\n",
    "        resolver.epsilon.set_value(np.float32(current_epsilon))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%10 ==0:\n",
    "\n",
    "        ##update learning curves\n",
    "        full_loss, q_loss, l2_penalty, avg_reward_current = evaluation_fun()\n",
    "        ma_reward_current = (1-alpha)*ma_reward_current + alpha*avg_reward_current\n",
    "        score_log[\"expected e-greedy reward\"][epoch_counter] = ma_reward_current\n",
    "        \n",
    "        \n",
    "        \n",
    "        #greedy train\n",
    "        resolver.epsilon.set_value(0)\n",
    "        update_pool(env,pool,replay_seq_len)\n",
    "\n",
    "        avg_reward_greedy = evaluation_fun()[-1]\n",
    "        ma_reward_greedy = (1-alpha)*ma_reward_greedy + alpha*avg_reward_greedy\n",
    "        score_log[\"expected greedy reward\"][epoch_counter] = ma_reward_greedy\n",
    "        \n",
    "        \n",
    "        #back to epsilon-greedy\n",
    "        resolver.epsilon.set_value(np.float32(current_epsilon))\n",
    "        update_pool(env,pool,replay_seq_len)\n",
    "\n",
    "        print(\"epoch %i,loss %.5f, epsilon %.5f, rewards: ( e-greedy %.5f, greedy %.5f) \"%(\n",
    "            epoch_counter,full_loss,current_epsilon,ma_reward_current,ma_reward_greedy))\n",
    "        print(\"rec %.3f reg %.3f\"%(q_loss,l2_penalty))\n",
    "\n",
    "    if epoch_counter %100 ==0:\n",
    "        print(\"Learning curves:\")\n",
    "        score_log.plot()\n",
    "\n",
    "\n",
    "        print(\"Random session examples\")\n",
    "        display_sessions()\n",
    "    \n",
    "    #run several sessions of game, record videos and save obtained results\n",
    "    if epoch_counter %1000 ==0:\n",
    "        \n",
    "        save_path = 'videos/Seaquest-v0_' + str(epoch_counter)\n",
    "\n",
    "        subm_env = gym.make(GAME_TITLE)\n",
    "\n",
    "        #starting monitor. This setup does not write videos\n",
    "        #subm_env.monitor.start(save_path,lambda i: False,force=True)\n",
    "\n",
    "        #this setup does\n",
    "        subm_env.monitor.start(save_path,force=True)\n",
    "\n",
    "        rws = []\n",
    "\n",
    "        for i_episode in xrange(250):\n",
    "\n",
    "            #initial observation\n",
    "            observation = subm_env.reset()\n",
    "            #initial memory\n",
    "            prev_memories = \"zeros\"\n",
    "\n",
    "            s_reward =0.\n",
    "            t = 0\n",
    "            while True:\n",
    "\n",
    "                action,new_memories = step([observation],prev_memories,batch_size=1)\n",
    "                observation, reward, done, info = subm_env.step(action[0])\n",
    "\n",
    "                s_reward += reward\n",
    "\n",
    "                prev_memories = new_memories\n",
    "                if done:\n",
    "                    print(\"Episode finished after {} timesteps, rw = {}\".format(t+1,s_reward))\n",
    "                    rws.append(s_reward)\n",
    "                    break\n",
    "                t+=1\n",
    "\n",
    "        subm_env.monitor.close()\n",
    "\n",
    "        rws = np.array(rws)\n",
    "        np.savez(open('rws4histSeaquest_'+str(epoch_counter)+'.npz', 'wb'), rws=rws)\n",
    "        \n",
    "        \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_path = 'videos/MSPacman-v0_' + str(epoch_counter-1)\n",
    "\n",
    "subm_env = gym.make(GAME_TITLE)\n",
    "\n",
    "#starting monitor. This setup does not write videos\n",
    "#subm_env.monitor.start(save_path,lambda i: False,force=True)\n",
    "\n",
    "#this setup does\n",
    "subm_env.monitor.start(save_path,force=True)\n",
    "\n",
    "rws = []\n",
    "\n",
    "for i_episode in xrange(220):\n",
    "\n",
    "    #initial observation\n",
    "    observation = subm_env.reset()\n",
    "    #initial memory\n",
    "    prev_memories = \"zeros\"\n",
    "\n",
    "    s_reward =0.\n",
    "    t = 0\n",
    "    while True:\n",
    "\n",
    "        action,new_memories = step([observation],prev_memories,batch_size=1)\n",
    "        observation, reward, done, info = subm_env.step(action[0])\n",
    "\n",
    "        s_reward += reward\n",
    "\n",
    "        prev_memories = new_memories\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps, rw = {}\".format(t+1,s_reward))\n",
    "            rws.append(s_reward)\n",
    "            break\n",
    "        t+=1\n",
    "\n",
    "subm_env.monitor.close()\n",
    "\n",
    "rws = np.array(rws)\n",
    "np.savez(open('rws4hist_'+str(epoch_counter-1)+'.npz', 'wb'), rws=rws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(rws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results\n",
    " * Here we plot learning curves and sample testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_log.plot(\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Random session examples\")\n",
    "display_sessions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "lc = {'e-greedy':score_log['expected e-greedy reward'], 'greedy':score_log['expected greedy reward']}\n",
    "\n",
    "with open(str(epoch_counter-1)+'iter_lc.pickle', 'wb') as handle:\n",
    "    lc = pickle.dump(lc, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Submission\n",
    "Here we simply run the OpenAI gym submission code and view scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resolver.epsilon.set_value(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_path = '/tmp/AgentNet-simplenet-Seaquest-v0-Recording0'\n",
    "\n",
    "subm_env = gym.make(GAME_TITLE)\n",
    "\n",
    "#starting monitor. This setup does not write videos\n",
    "subm_env.monitor.start(save_path,lambda i: False,force=True)\n",
    "\n",
    "#this setup does\n",
    "#subm_env.monitor.start(save_path,force=True)\n",
    "\n",
    "\n",
    "for i_episode in xrange(200):\n",
    "    \n",
    "    #initial observation\n",
    "    observation = subm_env.reset()\n",
    "    #initial memory\n",
    "    prev_memories = \"zeros\"\n",
    "    \n",
    "    \n",
    "    t = 0\n",
    "    while True:\n",
    "\n",
    "        action,new_memories = step([observation],prev_memories,batch_size=1)\n",
    "        observation, reward, done, info = subm_env.step(action[0])\n",
    "        \n",
    "        prev_memories = new_memories\n",
    "        if done:\n",
    "            print \"Episode finished after {} timesteps\".format(t+1)\n",
    "            break\n",
    "        t+=1\n",
    "\n",
    "subm_env.monitor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[monitor.close() for monitor in gym.monitoring._open_monitors()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "gym.upload(save_path,\n",
    "           \n",
    "           #this notebook\n",
    "           writeup=<url to my gist>, \n",
    "           \n",
    "           #your api key\n",
    "           api_key=<my_own_api_key>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Once you got it working,\n",
    "Try building a network that maximizes the final score\n",
    "\n",
    "* Moar lasagne stuff: convolutional layers, batch normalization, nonlinearities and so on\n",
    "* Recurrent agent memory layers, GRUMemoryLayer, etc\n",
    "* Different reinforcement learning algorithm (p.e. agent-critic), other parameters\n",
    "* Experience replay pool\n",
    "\n",
    "\n",
    "Look for examples? Try examples/Deep Kung Fu for most of these features\n",
    "\n",
    "\n",
    "You can also try to expand to a different game: \n",
    " * all OpenAI Atari games are already compatible, you only need to change GAME_TITLE\n",
    " * Other discrete action space environments are also accessible this way\n",
    " * For continuous action spaces, either discretize actions or use continuous RL algorithms (e.g. .learning.dpg_n_step)\n",
    " * Adapting to a custom non-OpenAI environment can be done with a simple wrapper\n",
    "\n",
    " \n",
    "__Good luck!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gym.upload?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
